## Finetune 简介

常用微调模式：
- 增量微调: 学习垂类领域知识 -> **pretrained**
- 指令跟随：偏对话 -> **instructed**


基座模型->**增量微调**->垂类基座模型->**指令跟随**->垂类对话模型


### 指令跟随

为了得到能够实际对话的LLM。



#### 角色

**通常**三种角色：
System: 给定上下文信息
User:实际提问题的用户
Assistant:根据用户输入，结合System的上下文信息，作出回答


#### 对话模板

微调阶段需要按照不同的模型的不同模板进行组装；

预测阶段不需要进行模板组装，系统会将用户的输入进行填充；

指令跟随的微调希望模型学会的是回答，所以用模型的输出计算Loss。

### 增量微调

陈述句。


### LoRA & QLoRA

**LoRA: LOW-RANK ADAPTATION OF LARGE LANG Models**

LLM 的参数量主要集中在模型中的 **Linear**，训练这些参数会耗费大量的显存。

LoRA 通过在原本的 Linear 旁，新增一个支路，包含两个连续的小Linear， 新增的这个支路通常叫做 **Adapter**

Adapter 参数量远小于原本的 Linear，能大幅降低训练的显存消耗

[LoRA: Low-Rank Adaptation of Large Language Models
](http://arxiv.org/abs/2106.09685)

[QLoRA: Efficient Finetuning of Quantized LLMs
](http://arxiv.org/abs/2305.14314)

![image](https://github.com/lvoooo/internLM-learning/assets/16740247/8c2da5a0-a79d-47ae-9dbe-e4917a1f3951)

Adapter 部分参数就是 LoRA 模型文件。

![image](https://github.com/lvoooo/internLM-learning/assets/16740247/1bfeea4c-bbfc-4ffb-8c23-180563dffff9)

全量微调：
- Base Model 参与训练并更新参数
- 需要保存 Base Model 中参数的优化器状态

LoRA：
- Base Model 只参与Forward
- 只有 Adapter 部分 Backward 更新参数
- 只需保存 Adapter 中参数的优化器状态

QLoRA：
- **Base Model 量化为 4-bit**
- **优化器状态在 CPU与 GPU 间 Offload**
- Base Model 只参与 Forward
- 只有 Adapter 部分 Backward 更新参数
- 只需保存 Adapter 中参数的优化器状态


### XTuner
- 多种微调算法
- 适配多种开源生态
- 自动优化加速
- 适配多种显卡
- 支持：对话、工具类、数据流处理（数据集映射函数、对话模板映射函数）、多样本拼接

#### 自定义训练

1.安装
```shell
pip install xtuner
```

2.挑选配置模板

```shell
xtuner list-cfg -p internlm_20b
```

3.一键训练
```shell
xtuner train internlm_20b_qlora_oasst1_512_e3
```

**Config 命名规则**
模型名： internlm_20b，无 chat 代表是基座模型
使用算法：qlora
数据集：oasst1
数据长度：512
Epoch：e3, epoch 3

拷贝模板
```shell
xtuner copy-cfg internlm_20b_qlora_oasst1_512_e3 ./
````
编辑
```shell
vi internlm_20b_qlora_oasst1_512_e3_copy.py
```

启动训练

```shell
xtuner train internlm_20b_qlora_oasst1_512_e3_copy.py
```

常用超参
data_path： 数据路径或 HuggingFace 仓库名
max_length：单条数据最大 Token 数，超过则截断
pack_to_max_length：是否将多条短数据拼接到 max_length。提高 GPU 利用率
accumulative _counts：梯度累积，每多少次 backward 更新—次参数
evaluation_inputs：训练过程中，会根据给定的问题进行推理，便于观测训练状态
evaluation_freq：Evaluation 的评测间隔 iter 数

对话

Float 16 模型对话：
```shell
xtuner chat internlm/internlm-chat-20b
```

4bit 模型对话
```shell
xtuner chat internlm/internlm-chat-20b --bits 4
```

加载 Adapter 模型对话
```shell
xtuner chat internlm/internlm-chat-20b --adapater $ADAPTER_DIR
```

#### 小显存玩LLM
- Flash Attention
- DeepSpeed ZeRo:  --deepsped deepspeed_zero3/deepspeed_zero2

![image](https://github.com/lvoooo/internLM-learning/assets/16740247/b97732ac-d110-4d9f-8dd1-e97f0d234bcf)



